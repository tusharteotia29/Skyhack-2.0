{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":9568803,"sourceType":"datasetVersion","datasetId":5832271},{"sourceId":69834,"sourceType":"modelInstanceVersion","modelInstanceId":57466,"modelId":78150}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Use latest version environment and TPUs ( Not GPU )","metadata":{}},{"cell_type":"code","source":"!pip install -q -U keras-nlp tensorflow-text\n# Install tensorflow-cpu so tensorflow does not attempt to access the TPU.\n!pip install -q -U tensorflow-cpu","metadata":{"execution":{"iopub.status.busy":"2024-10-09T14:34:36.419386Z","iopub.execute_input":"2024-10-09T14:34:36.419907Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import jax\n\njax.devices()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# The Keras 3 distribution API is only implemented for the JAX backend for now\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n# Pre-allocate all TPU memory to minimize memory fragmentation and allocation overhead.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:26.511813Z","iopub.execute_input":"2024-07-27T04:04:26.512189Z","iopub.status.idle":"2024-07-27T04:04:26.516278Z","shell.execute_reply.started":"2024-07-27T04:04:26.51214Z","shell.execute_reply":"2024-07-27T04:04:26.51551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:26.517204Z","iopub.execute_input":"2024-07-27T04:04:26.517527Z","iopub.status.idle":"2024-07-27T04:04:29.404347Z","shell.execute_reply.started":"2024-07-27T04:04:26.517495Z","shell.execute_reply":"2024-07-27T04:04:29.403479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_mesh = keras.distribution.DeviceMesh(\n    (3, 6),\n    [\"batch\", \"model\"],\n    devices=keras.distribution.list_devices(),\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:29.406293Z","iopub.execute_input":"2024-07-27T04:04:29.40678Z","iopub.status.idle":"2024-07-27T04:04:29.411026Z","shell.execute_reply.started":"2024-07-27T04:04:29.40674Z","shell.execute_reply":"2024-07-27T04:04:29.410235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dim = \"model\"\n\nlayout_map = keras.distribution.LayoutMap(device_mesh)\n\n# Weights that match 'token_embedding/embeddings' will be sharded on 8 TPUs\nlayout_map[\"token_embedding/embeddings\"] = (model_dim, None)\n# Regex to match against the query, key and value matrices in attention layers\nlayout_map[\"decoder_block.*attention.*(query|key|value)/kernel\"] = (model_dim, None, None)\nlayout_map[\"decoder_block.*attention_output/kernel\"] = (model_dim, None, None)\nlayout_map[\"decoder_block.*ffw_gating.*/kernel\"] = (None, model_dim)\nlayout_map[\"decoder_block.*ffw_linear/kernel\"] = (model_dim, None)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:29.411945Z","iopub.execute_input":"2024-07-27T04:04:29.412201Z","iopub.status.idle":"2024-07-27T04:04:29.429592Z","shell.execute_reply.started":"2024-07-27T04:04:29.412174Z","shell.execute_reply":"2024-07-27T04:04:29.428903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_surrogates(text):\n    return ''.join(char for char in text if not (0xD800 <= ord(char) <= 0xDFFF))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:29.430349Z","iopub.execute_input":"2024-07-27T04:04:29.430592Z","iopub.status.idle":"2024-07-27T04:04:29.440359Z","shell.execute_reply.started":"2024-07-27T04:04:29.430567Z","shell.execute_reply":"2024-07-27T04:04:29.439674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Define the prompt template and EOS token\nalpaca_prompt = \"\"\"Below is a conversation, identify the reason for the conversation that the client had to call\n\n# Conversation:\n{}\n\n# Output:\n{}\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n\n# Define the formatting function\ndef formatting_prompts_func(df):\n    Text = df[\"call_transcript\"]\n    outputs = df[\"primary_call_reason\"]\n    texts = []\n    for instruction, output in zip(Text, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n        texts.append(text)\n    return texts\n\ndf['formatted_text'] = formatting_prompts_func(df)\n\n# View the result\n#df[['text', 'formatted_text']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas import read_csv, DataFrame\n\n\nraw_train_dataset = read_csv('') #filepath\n\n\ntrain_dataset = DataFrame({\n    'text' : raw_train_dataset[input_columns].apply(lambda x: remove_surrogates(x)),\n    'label' : raw_train_dataset[label_columns].apply(lambda x: x.values.tolist(), axis=1)\n})","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-27T04:04:29.441191Z","iopub.execute_input":"2024-07-27T04:04:29.441429Z","iopub.status.idle":"2024-07-27T04:04:52.03838Z","shell.execute_reply.started":"2024-07-27T04:04:29.441403Z","shell.execute_reply":"2024-07-27T04:04:52.037521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_parallel = keras.distribution.ModelParallel(\n    layout_map=layout_map,\n    batch_dim_name=\"batch\",\n)\n\nkeras.distribution.set_distribution(model_parallel)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:52.039292Z","iopub.execute_input":"2024-07-27T04:04:52.039529Z","iopub.status.idle":"2024-07-27T04:04:52.043277Z","shell.execute_reply.started":"2024-07-27T04:04:52.039505Z","shell.execute_reply":"2024-07-27T04:04:52.042543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#keras.config.set_floatx(\"bfloat16\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma2/keras/gemma2_instruct_9b_en/1\")\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:04:52.044206Z","iopub.execute_input":"2024-07-27T04:04:52.044474Z","iopub.status.idle":"2024-07-27T04:07:17.610825Z","shell.execute_reply.started":"2024-07-27T04:04:52.044447Z","shell.execute_reply":"2024-07-27T04:07:17.610039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gemma_lm.backbone.enable_lora(rank=16)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:17.611775Z","iopub.execute_input":"2024-07-27T04:07:17.612026Z","iopub.status.idle":"2024-07-27T04:07:18.398538Z","shell.execute_reply.started":"2024-07-27T04:07:17.612001Z","shell.execute_reply":"2024-07-27T04:07:18.397688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in gemma_lm._backbone.layers[:16]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.399506Z","iopub.execute_input":"2024-07-27T04:07:18.399766Z","iopub.status.idle":"2024-07-27T04:07:18.404759Z","shell.execute_reply.started":"2024-07-27T04:07:18.39974Z","shell.execute_reply":"2024-07-27T04:07:18.404095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.405572Z","iopub.execute_input":"2024-07-27T04:07:18.405872Z","iopub.status.idle":"2024-07-27T04:07:18.438794Z","shell.execute_reply.started":"2024-07-27T04:07:18.405844Z","shell.execute_reply":"2024-07-27T04:07:18.438138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_fn(text, label=None):\n    preprocessed = gemma_lm._preprocessor(text, sequence_length=1024)[0]\n    # Ensure the preprocess function returns only the necessary inputs\n    return {'token_ids' : preprocessed['token_ids'], 'padding_mask' : preprocessed['padding_mask']}, label if label is not None else text","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.441038Z","iopub.execute_input":"2024-07-27T04:07:18.441284Z","iopub.status.idle":"2024-07-27T04:07:18.445386Z","shell.execute_reply.started":"2024-07-27T04:07:18.44126Z","shell.execute_reply":"2024-07-27T04:07:18.444669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import Input, Dense, Flatten, GlobalAveragePooling1D\nfrom keras import Model\n\ninputs = {\n    \"token_ids\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"token_ids\"),\n    \"padding_mask\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"padding_mask\"),\n}\nx = gemma_lm.backbone(inputs)\nprint(x.shape)\nx = GlobalAveragePooling1D()(x)\nprint(x.shape)\n\noutputs = Dense(54, 'softmax')(x)\nmodel = Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.446319Z","iopub.execute_input":"2024-07-27T04:07:18.446656Z","iopub.status.idle":"2024-07-27T04:07:18.747228Z","shell.execute_reply.started":"2024-07-27T04:07:18.446614Z","shell.execute_reply":"2024-07-27T04:07:18.746211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = keras.optimizers.AdamW(\n                learning_rate=5e-5,\n                weight_decay=0.01,)\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.748242Z","iopub.execute_input":"2024-07-27T04:07:18.748578Z","iopub.status.idle":"2024-07-27T04:07:18.754139Z","shell.execute_reply.started":"2024-07-27T04:07:18.74855Z","shell.execute_reply":"2024-07-27T04:07:18.753415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.755045Z","iopub.execute_input":"2024-07-27T04:07:18.75531Z","iopub.status.idle":"2024-07-27T04:07:18.768823Z","shell.execute_reply.started":"2024-07-27T04:07:18.755284Z","shell.execute_reply":"2024-07-27T04:07:18.768097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nds = tf.data.Dataset.from_tensor_slices((train_dataset.text.values, raw_train_dataset[label_columns].values)).batch(4).map(preprocess_fn)\nds = ds.shuffle(ds.cardinality())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:18.769643Z","iopub.execute_input":"2024-07-27T04:07:18.76989Z","iopub.status.idle":"2024-07-27T04:07:19.247006Z","shell.execute_reply.started":"2024-07-27T04:07:18.769864Z","shell.execute_reply":"2024-07-27T04:07:19.246007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_split = ds.take(int(len(ds)*0.9))\nval_split = ds.skip(int(len(ds)*0.9)).take(int(len(ds)*0.1))\nhistories = model.fit(train_split, validation_data=[val_split], epochs=1, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T04:07:19.248003Z","iopub.execute_input":"2024-07-27T04:07:19.248245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nlayer = model.get_layer(name='dense')\nweights = layer.get_weights()\nkernel, bias = weights\n\n# Save the kernel and bias separately\nnp.save('dense_1_kernel.npy', kernel)\nnp.save('dense_1_bias.npy', bias)\nmodel.layers[2].save_lora_weights(\"model.lora.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}